{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from allennlp.modules.token_embedders.elmo_token_embedder import ElmoTokenEmbedder\n",
    "\n",
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "from allennlp.data import Token, Vocabulary, TokenIndexer, Tokenizer\n",
    "from allennlp.data.fields import ListField, TextField\n",
    "from allennlp.data.token_indexers import (\n",
    "    SingleIdTokenIndexer,\n",
    "    TokenCharactersIndexer,\n",
    "    ELMoTokenCharactersIndexer,\n",
    "    PretrainedTransformerIndexer,\n",
    "    PretrainedTransformerMismatchedIndexer,\n",
    ")\n",
    "from allennlp.data.tokenizers import (\n",
    "    CharacterTokenizer,\n",
    "    PretrainedTransformerTokenizer,\n",
    "    SpacyTokenizer,\n",
    "    WhitespaceTokenizer,\n",
    ")\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import (\n",
    "    Embedding,\n",
    "    TokenCharactersEncoder,\n",
    "    ElmoTokenEmbedder,\n",
    "    PretrainedTransformerEmbedder,\n",
    "    PretrainedTransformerMismatchedEmbedder,\n",
    ")\n",
    "from allennlp.nn import util as nn_util\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering, DBSCAN\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pretrained elmo (can be truncated later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file_path=\"../../slovenian-elmo/options.json\"\n",
    "weight_file_path=\"../../slovenian-elmo/slovenian-elmo-weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo tokens: [Kako, je, stari]\n",
      "ELMo tensors: {'elmo_tokens': {'elmo_tokens': tensor([[259,  76,  98, 108, 112, 260, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 107, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261],\n",
      "        [259, 116, 117,  98, 115, 106, 260, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
      "         261, 261, 261, 261, 261, 261, 261, 261]])}}\n",
      "ELMo embedded tokens: tensor([[[-0.1121, -0.0000, -0.1658,  ...,  0.0000, -0.0000,  0.2513],\n",
      "         [-0.5308,  0.0000,  0.2203,  ..., -0.0000,  0.0000, -0.1073],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ..., -0.4340,  0.4817, -0.0000]]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tokenizer: Tokenizer = WhitespaceTokenizer()\n",
    "token_indexer: TokenIndexer = ELMoTokenCharactersIndexer()\n",
    "vocab = Vocabulary()\n",
    "text = \"Kako je stari\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(\"ELMo tokens:\", tokens)\n",
    "text_field = TextField(tokens, {\"elmo_tokens\": token_indexer})\n",
    "text_field.index(vocab)\n",
    "token_tensor = text_field.as_tensor(text_field.get_padding_lengths())\n",
    "print(\"ELMo tensors:\", token_tensor)\n",
    "\n",
    "# We're using a tiny, toy version of ELMo to demonstrate this.\n",
    "elmo_embedding = ElmoTokenEmbedder(\n",
    "    options_file=options_file_path,\n",
    "    weight_file=weight_file_path)\n",
    "\n",
    "embedder = BasicTextFieldEmbedder(token_embedders={\"elmo_tokens\": elmo_embedding})\n",
    "\n",
    "tensor_dict = text_field.batch_tensors([token_tensor])\n",
    "embedded_tokens = embedder(tensor_dict)\n",
    "print(\"ELMo embedded tokens:\", embedded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.0560, -0.0472, -0.0829,  ...,  0.0517, -0.0407,  0.1257],\n",
      "         [-0.2654,  0.2074,  0.1101,  ..., -0.1543,  0.2586, -0.0537],\n",
      "         [ 0.0599,  0.1776, -0.4385,  ..., -0.2170,  0.2408, -0.1374]],\n",
      "\n",
      "        [[-0.0560, -0.0472, -0.0829,  ...,  0.0517, -0.0407,  0.1257],\n",
      "         [-0.2654,  0.2074,  0.1101,  ..., -0.1543,  0.2586, -0.0537],\n",
      "         [ 0.0599,  0.1776, -0.4385,  ..., -0.2170,  0.2408, -0.1374]],\n",
      "\n",
      "        [[-0.0560, -0.0472, -0.0829,  ...,  0.0517, -0.0407,  0.1257],\n",
      "         [-0.2654,  0.2074,  0.1101,  ..., -0.1543,  0.2586, -0.0537],\n",
      "         [ 0.0599,  0.1776, -0.4385,  ..., -0.2170,  0.2408, -0.1374]]],\n",
      "       grad_fn=<CopySlices>)]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "# Note the \"1\", since we want only 1 output representation for each token.\n",
    "elmo = Elmo(options_file=options_file_path,\n",
    "            weight_file=weight_file_path, num_output_representations=1, dropout=0)\n",
    "\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['Kako', 'je', 'stari'], ['Kako', 'je', 'stari'], ['Kako', 'je', 'stari']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)\n",
    "print(embeddings['elmo_representations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings['elmo_representations'][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some utility functions which are used\n",
    "def cos_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "def remove_diplicate_sentences(a):\n",
    "    b_set = set(map(tuple,a))  #need to convert the inner lists to tuples so they are hashable\n",
    "    b = list(map(list,b_set)) #Now convert tuples back into lists (maybe unnecessary?)\n",
    "    return b\n",
    "\n",
    "def convert_to_lowercase(sentences):\n",
    "    res=[]\n",
    "    for i in sentences:\n",
    "        res.append(list(map(str.lower,i)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the \"1\", since we want only 1 output representation for each token.\n",
    "elmo = Elmo(options_file=options_file_path,\n",
    "            weight_file=weight_file_path, num_output_representations=1, dropout=0)\n",
    "\n",
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['Kako', 'je', 'stari'], ['Kako', 'je', 'stari'], ['Kako', 'je', 'stari']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)\n",
    "print(embeddings['elmo_representations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['leto', 'dan', 'konec', 'svet', 'stran', 'mesto', 'šola', 'ura',\n",
       "       'beseda', 'pot', 'red', 'zakon', 'zadeva', 'srce', 'tema',\n",
       "       'resnica', 'moški', 'vloga', 'kraj', 'stanje', 'škoda', 'film',\n",
       "       'večer', 'vrh', 'jutro', 'kazen', 'oblast', 'račun', 'novica',\n",
       "       'milijon', 'par', 'krog', 'tip', 'punca', 'sila', 'vir', 'las',\n",
       "       'akcija', 'meter', 'prst', 'kri', 'stik', 'grad', 'znak', 'lik',\n",
       "       'direktor', 'vodja', 'raven', 'kolo', 'rob', 'gost', 'duh',\n",
       "       'praznik', 'vest', 'korist', 'vedenje', 'tek', 'kup', 'otok',\n",
       "       'razstava', 'bitje', 'motor', 'karta', 'nevarnost', 'hitrost',\n",
       "       'kos', 'zob', 'stroj', 'kamen', 'župan', 'šef', 'vrtec', 'kot',\n",
       "       'deček', 'avgust', 'tok', 'jezero', 'klop', 'čelo', 'hip', 'kupec',\n",
       "       'pojav', 'čaj', 'postava', 'dolg', 'standard', 'jesen', 'rak',\n",
       "       'grob', 'plus', 'les', 'vez', 'polica', 'minus', 'plan', 'posoda',\n",
       "       'restavracija', 'jok', 'krilo', 'sol', 'rod', 'stres', 'trditev',\n",
       "       'faks', 'sled', 'gol', 'župnik', 'servis', 'prid', 'ustava',\n",
       "       'mora', 'pop', 'lokal', 'prevod', 'bazen', 'veda', 'plaža',\n",
       "       'pesek', 'opravljanje', 'bolnica', 'hoja', 'raj', 'maček', 'baza',\n",
       "       'kocka', 'sejem', 'bar', 'hodnik', 'lisica', 'skala', 'lev', 'vek',\n",
       "       'talent', 'peč', 'termin', 'krivec', 'lega', 'tableta',\n",
       "       'pogajanje', 'obrat', 'kampanja', 'očka', 'med', 'stop', 'plast',\n",
       "       'golf', 'mina', 'kip', 'pod', 'para', 'prilika', 'slovo', 'piknik',\n",
       "       'boja', 'krajina', 'nona', 'odpuščanje', 'draga', 'faktor', 'bit',\n",
       "       'vodnik', 'razgled', 'popoldan', 'pol', 'obresti', 'paša', 'pust',\n",
       "       'teza', 'koda', 'predsodek', 'instrument', 'smuč', 'pečica',\n",
       "       'nestrpnost', 'lok', 'bob', 'obrt', 'kopanje', 'rez', 'pok',\n",
       "       'jarek', 'peščica', 'metal', 'palček', 'ruta', 'solo', 'hod'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../ccGigaFida/results/data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "with open('../../ccGigaFida/results/data_lema.json') as json_file:\n",
    "    data_lema = json.load(json_file)\n",
    "with open('../../ccGigaFida/results/data_pos.json') as json_file:\n",
    "    data_len = json.load(json_file)\n",
    "\n",
    "words = np.load(\"../../ccGigaFida/words.npy\")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_number_of_words=8\n",
    "for keyword in ['rak']:\n",
    "    all_sentences2=data[keyword][:500]\n",
    "    all_sentences_lema2=data_lema[keyword][:500]\n",
    "\n",
    "    all_sentences = []\n",
    "    all_sentences_lema = []\n",
    "    for sentence, sentence_lema in zip(all_sentences2, all_sentences_lema2):\n",
    "        if len(sentence) >= min_number_of_words and sentence_lema not in all_sentences_lema:\n",
    "            all_sentences.append(sentence)\n",
    "            all_sentences_lema.append(sentence_lema)\n",
    "    \n",
    "    #all_sentences = convert_to_lowercase(all_sentences)\n",
    "    all_sentences = convert_to_lowercase(all_sentences)\n",
    "    all_embeddings=np.zeros((len(all_sentences),1024))\n",
    "    \n",
    "    character_ids = batch_to_ids(all_sentences)\n",
    "    embeddings = elmo(character_ids) #rip RAM\n",
    "    \n",
    "    for i in range(len(all_sentences)): #iterate through the sentences for the given keyword\n",
    "        \n",
    "        keyword_position = all_sentences_lema[i].index(keyword)\n",
    "        all_embeddings[i,:]=embeddings['elmo_representations'][0].detach().numpy()[i][keyword_position]\n",
    "        \n",
    "    \n",
    "    break #this break means that we terminate on the first word\n",
    "    \n",
    "del embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate pairwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The bigger it is the more similar the senctences \n",
    "similarities={}\n",
    "for i in range(all_embeddings.shape[0]):\n",
    "    for j in range(i+1,all_embeddings.shape[0],1):\n",
    "        similarities[str(i)+'-'+str(j)] = cos_similarity(all_embeddings[i,:], all_embeddings[j,:])\n",
    "        \n",
    "similarities = dict(sorted(similarities.items(), key=lambda x:x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze worst 50 distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "2)vod. 1. pasteur sedmak eda 2. ovratnik tina turner 3. stereotiper lineal 4. todo epoleta cj as 5. omika kaša rak alva 6. jonija rt ava nika 7. abas nojevo jajce ab 8. ni tridentčanke 9. klokotanje ntare ns 10. astana jako uvodnik 11\n",
      "-----\n",
      "1)eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "2)to se zgodi ker večina zdravil proti raku prizadene delovanje kostnega mozga in zmanjša njegovo sposobnost za tvorbo belih krvnih celic ki premagujejo številne vrste okužb\n",
      "-----\n",
      "1)eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "2)za ustrezno zdravljenje je treba rak na prostati diagnosticirati dovolj zgodaj saj je ozdravljiv le v začetnem stadiju\n",
      "-----\n",
      "1)eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "2)po podatkih registra raka slovenije še vedno narašča število novih primerov raka vendar je to naraščanje povezano tudi s prizadevanji za zgodnejše odkrivanje raka\n",
      "-----\n",
      "1)eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "2)strokovnjaki menijo da sta najpogostejši duševni motnji pri bolnikih z rakom poleg motenj prilagajanja depresija in anksioznost ki se lahko pojavljata v kombinaciji ali posamično\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "similarities_keys = list(similarities.keys())\n",
    "for key in similarities_keys[0:5]:\n",
    "    first_sentence_idx, second_sentence_idx = map(int, key.split('-'))\n",
    "        \n",
    "    first_sent, second_sent = ' '.join(all_sentences[first_sentence_idx]), ' '.join(all_sentences[second_sentence_idx])\n",
    "    \n",
    "    print(\"1)\"+first_sent+'\\n2)'+second_sent)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)lani smo začeli s projektom mi podpiramo prihodnost ki je namenjen otrokom obolelim za rakom\n",
      "2)zbran denar tudi z dražbo umetniških del bodo namenili za igrala otrokom obolelih za rakom\n",
      "-----\n",
      "1)moja žena boluje za kostnim rakom operacija stane dobre dva milijona tolarjev\n",
      "2)zraven sebe je imel napis moja žena boluje za kostnim rakom operacija stane dobre dva milijona tolarjev\n",
      "-----\n",
      "1)to se mogoče zdi presenetljivo glede na to da nekateri virusi nedvomno povzročajo raka\n",
      "2)izidi bi bili lahko presenetljivi glede na to da nekateri virusi nedvomno povzročajo raka\n",
      "-----\n",
      "1)pomemben dosežek v boju zoper raka na materničnem vratu pomeni cepivo izdelano posebej za preprečevanje nastanka tumorjev v področju spolovil in rodil\n",
      "2)pomemben dosežek v boju zoper raka na materničnem vratu pomeni cepivo izdelano posebej za preprečevanje nastanka tumorjev\n",
      "-----\n",
      "1)kljub temu obstaja domneva da se zmanjša tveganje za nastanek nekaterih pediatričnih rakov pri otrocih ki so bili izpostavljeni okužbam v prvih letih življenja\n",
      "2)navzlic temu domnevajo da se zmanjša tveganje za nastanek nekaterih pediatričnih rakov pri otrocih ki so bili izpostavljeni okužbam v prvih letih življenja\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "similarities_keys = list(similarities.keys())\n",
    "for key in similarities_keys[-5:]:\n",
    "    first_sentence_idx, second_sentence_idx = map(int, key.split('-'))\n",
    "        \n",
    "    first_sent, second_sent = ' '.join(all_sentences[first_sentence_idx]), ' '.join(all_sentences[second_sentence_idx])\n",
    "    \n",
    "    print(\"1)\"+first_sent+'\\n2)'+second_sent)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity and distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_embeddings.shape)\n",
    "distance_matrix=(pairwise_distances(all_embeddings,metric=\"cosine\"))\n",
    "similarity_matrix=1-distance_matrix\n",
    "\n",
    "#density plot\n",
    "#similarity_matrix_flatten = similarity_matrix.reshape(len(similarity_matrix)**2)\n",
    "#density = gaussian_kde(similarity_matrix_flatten)\n",
    "#density.covariance_factor = lambda : .5\n",
    "#len(similarity_matrix_flatten)\n",
    "#plt.plot(similarity_matrix_flatten, density(similarity_matrix_flatten))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Not mandatory) !!!\n",
    "'''best_scores_indices=[]\n",
    "for i in list(distances.keys()):\n",
    "    first, second = i.split('-')\n",
    "    if distances[i]>0.90:\n",
    "        best_scores_indices.append(first)\n",
    "        best_scores_indices.append(second)\n",
    "\n",
    "\n",
    "best_scores_indices=(np.unique(best_scores_indices))\n",
    "best_scores_indices = best_scores_indices.astype(int)\n",
    "all_embeddings_selected = all_embeddings[best_scores_indices, :]\n",
    "\n",
    "distance_matrix_selected=(pairwise_distances(all_embeddings_selected,metric=\"cosine\"))\n",
    "print(len(all_embeddings_selected))\n",
    "\n",
    "all_sentences_selected = []\n",
    "for i in best_scores_indices:\n",
    "    all_sentences_selected.append(all_sentences[i])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 356, 1: 1})\n",
      "Counter({0: 337, 1: 20})\n",
      "Counter({1: 314, 0: 41, 2: 2})\n"
     ]
    }
   ],
   "source": [
    "# ‘complete’, ‘average’, ‘single’\n",
    "clusters = AgglomerativeClustering(affinity='precomputed', linkage='single', n_clusters=2).fit(distance_matrix)\n",
    "print(Counter(clusters.labels_))\n",
    "# ‘complete’, ‘average’, ‘single’\n",
    "clusters = AgglomerativeClustering(affinity='precomputed', linkage='average', n_clusters=2).fit(distance_matrix)\n",
    "print(Counter(clusters.labels_))\n",
    "# ‘complete’, ‘average’, ‘single’\n",
    "clusters = AgglomerativeClustering(affinity='precomputed', linkage='complete', n_clusters=3).fit(distance_matrix)\n",
    "print(Counter(clusters.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 : pav čep rak dar pek rep raca zidar pes top repa poper pismo slap račun večer pesem ščep rudar denar polenta potop raketa gobar pikapolonica odcep radirka dimnikar lupa sapa kopito kopica kaplja lopata toplice\n",
      "355 : vod. 1. pasteur sedmak eda 2. ovratnik tina turner 3. stereotiper lineal 4. todo epoleta cj as 5. omika kaša rak alva 6. jonija rt ava nika 7. abas nojevo jajce ab 8. ni tridentčanke 9. klokotanje ntare ns 10. astana jako uvodnik 11\n"
     ]
    }
   ],
   "source": [
    "for i,label in enumerate(clusters.labels_):\n",
    "    if label==2:\n",
    "        print(i,':', ' '.join(all_sentences[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marko\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:589: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 327, 1: 30})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral = SpectralClustering(2).fit_predict(distance_matrix)\n",
    "#spectral = SpectralClustering(2).fit(all_embeddings)\n",
    "Counter(spectral)\n",
    "#spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 327, 1: 30})\n",
      "17 : ob številnih receptih iz domačih in tujih logov nas nato popelje skozi bogastvo sladkovodnih in morskih rib mehkužcev glavonožcev školjk in rakov celo konzerviranih rib ter nas na prijeten način navdušuje za uživanje vsega tega bogastva hrane iz vode\n",
      "21 : kalcij je sestavina kalcijevega karbonata caco3 ki je nujno potreben za razvoj apnenčastega ogrodja koral je v oklepih rakov pa tudi v polžjih hišicah in školjčnih lupinah\n",
      "23 : ščetinozobke je torej treba postopoma privaditi na nove vrste hrane ki je dostopna v akvarističnih trgovinah ali ribarnicah zlasti na odrasle solinske rakce ali artemije mnogoščetince in druge črve koščke školjčnega mesa ter kozice in druge majhne rake\n",
      "24 : vse vrste sladkovodnih rakov so precej plašne živali in se dobro počutijo le v akvariju kjer imajo dovolj primernih skrivališč\n",
      "25 : pri pravilni prehrani in drugih ugodnih razmerah se raki levijo v rednih časovnih presledkih\n",
      "26 : v akvariju s kakovostno morsko vodo je gojenje teh rakov razmeroma enostavno imeti pa morajo dovolj ustreznih skrivališč\n",
      "61 : omar nisem ravno strokovnjak za horoskope vem pa da naj bi bili raki nežni vzkipljivi in malo zavidljivi\n",
      "65 : zato ni čudno da so planktonski raki iz jezera izginili kmalu po prvi drstitvi rib\n",
      "68 : v njej so bili nekdaj tudi raki zlasti veliko jih je bilo v pritoku iščice\n",
      "69 : eden od njih je sedel v čolnu in svetil s plamenico njegov tovariš pa je grabil rake z roko in jih metal v čoln\n",
      "76 : najbolj znani raki so potočni rak pa jastog in rakovice\n",
      "77 : v davnih časih so imeli nekatere rake za mlade ptiče\n",
      "78 : danes vemo da se je motil in da so vitičnjaki raki čeprav živijo pritrjeni\n",
      "85 : potrebujemo za enega 180 g kalamarov 150 g globinskih rakov 70 g oljčnega olja 10 g soli 1 g belega popra in 60 g okrasnega paradižnika\n",
      "90 : raki so izjemno preudarni in preden se česarkoli lotijo vedno vse temeljito premislijo\n",
      "91 : odnosi ujemajo se z raki rade so v družbi bikov ki poskrbijo za njihov blagor škorpijoni jih privlačijo umakniti se morajo dvojčkom levom in seveda tehtnicam\n",
      "93 : mreniči pisanci in blistavci ter veliko rakov koščakov\n",
      "140 : dobro vam denejo domače sadje presna zelenjava belo vino solata kislo zelje testenine in riž perutnina sladkovodne ribe in raki škodujejo pa vam ostre začimbe kot so poper ingver ostra paprika močno pečeno meso ali pripravljeno na žaru vse kar prav zaradi pečenja dobro diši na primer pražena kava česen čebula in visokoodstotne alkoholne pijače\n",
      "163 : samski raki pa boste poskušali pritegniti pozornost popolnoma napačnih ljudi\n",
      "204 : rake velikokrat srečamo kako brskajo po boljšem trgu ali pa hodijo od starinarnice do starinarnice\n",
      "207 : raki znajo biti zdaj mirni in skorajda brezosebni naslednji trenutek pa se že nejevoljno sprašujejo če jih ima ljubljena oseba še rada\n",
      "249 : ko je naslikal ducat različnih rib rakov hobotnic je spoznal da je\n",
      "250 : mnogi raki se ne držijo tako vzravnano kot bi se lahko\n",
      "251 : medtem ko so hitro užaljeni se raki pogosto ne zavedajo da so do drugih včasih tudi sami zelo ostri\n",
      "252 : mnogi raki so ne glede na svojo raso blede polti vendar to ni ključ do razpoznavanja njihovega zdravstvenega stanja\n",
      "253 : raki imajo ponavadi bujno domišljijo vendar tega svojega daru včasih ne razvijejo v tolikšnem obsegu kot bi ga lahko\n",
      "260 : slikovna križanka pro mama lam irun ivi tast sikorski george ag pbs loa gro peru šin knin obesek arena podhladitev smerokaz ds akela bor rep sadat in sesa konj atičanka amiš neca falk raki tkanine geslo george bush mlajši predsednik\n",
      "304 : zato je šel rakom žvižgat osnutek avdiovizualnega zakona\n",
      "332 : bolj od potapljačev so ogroženi ribiči ko čistijo svoje mreže trnkarji nabiralci rakov in školjk ki to počno ponoči\n",
      "355 : vod. 1. pasteur sedmak eda 2. ovratnik tina turner 3. stereotiper lineal 4. todo epoleta cj as 5. omika kaša rak alva 6. jonija rt ava nika 7. abas nojevo jajce ab 8. ni tridentčanke 9. klokotanje ntare ns 10. astana jako uvodnik 11\n"
     ]
    }
   ],
   "source": [
    "print(Counter(spectral))\n",
    "for i,label in enumerate(spectral):\n",
    "    if label==1:\n",
    "        print(i,':', ' '.join(all_sentences[i]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "004cf412bede8e677bcf59b14e1e48ce17b57f17e644433ba0ac6b9fba05c9bd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp-trimpleM': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
